{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Box:\n",
    "    r'''\n",
    "    Corner boxes are encoded as (xmin, ymin, xmax, ymax)\n",
    "    Center boxes are encoded as (center_x, center_y, width, height)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, corner):\n",
    "        self._corner = corner\n",
    "\n",
    "    @property\n",
    "    def corner(self):\n",
    "        return self._corner\n",
    "\n",
    "    @corner.setter\n",
    "    def corner(self, new_corner):\n",
    "        self._corner = new_corner\n",
    "\n",
    "    @property\n",
    "    def w(self):\n",
    "        '''\n",
    "        计算 bbox 的 宽\n",
    "        '''\n",
    "        return self.corner[2] - self.corner[0] + 1\n",
    "\n",
    "    @property\n",
    "    def h(self):\n",
    "        '''\n",
    "        计算 bbox 的 高\n",
    "        '''\n",
    "        return self.corner[3] - self.corner[1] + 1\n",
    "\n",
    "    @property\n",
    "    def whctrs(self):\n",
    "        '''\n",
    "        计算 bbox 的 中心坐标\n",
    "        '''\n",
    "        x_ctr = self.corner[0] + 0.5 * (self.w - 1)\n",
    "        y_ctr = self.corner[1] + 0.5 * (self.h - 1)\n",
    "        return [x_ctr, y_ctr]\n",
    "\n",
    "    @property\n",
    "    def corner2center(self):\n",
    "        '''\n",
    "        (xmin, ymin, xmax, ymax) to (center_x, center_y, width, height)\n",
    "        '''\n",
    "        return self.whctrs + [self.w, self.h]\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return self.w * self.h\n",
    "\n",
    "    def __and__(self, other):\n",
    "        '''\n",
    "        运算符：&，实现两个 box 的交集运算\n",
    "        '''\n",
    "        U = np.array([self.corner, other.corner])\n",
    "        xmin, ymin, xmax, ymax = np.split(U, 4, axis=1)\n",
    "        w = xmax.min() - xmin.max()\n",
    "        h = ymax.min() - ymin.max()\n",
    "        return w * h\n",
    "\n",
    "    def __or__(self, other):\n",
    "        '''\n",
    "        运算符：|，实现两个 box 的并集运算\n",
    "        '''\n",
    "        I = self & other\n",
    "        return self.size+other.size-I\n",
    "\n",
    "    def IoU(self, other):\n",
    "        I = self & other\n",
    "        U = self | other\n",
    "        return I / U\n",
    "\n",
    "\n",
    "class Anchor(Box):\n",
    "    r'''\n",
    "     Parameters\n",
    "    ----------\n",
    "    stride : int\n",
    "        Feature map stride with respect to original image.\n",
    "        This is usually the ratio between original image size and feature map size.\n",
    "    base_size : int\n",
    "        The width(and height) of reference anchor box.\n",
    "    ratios : iterable of float\n",
    "        The aspect ratios of anchor boxes. We expect it to be a list or tuple.\n",
    "    scales : iterable of float\n",
    "        The areas of anchor boxes.\n",
    "        We use the following form to compute the shapes of anchors:\n",
    "\n",
    "        .. math::\n",
    "\n",
    "            width_{anchor} = size_{base} \\times scale \\times \\sqrt{ 1 / ratio}\n",
    "            height_{anchor} = size_{base} \\times scale \\times \\sqrt{ratio}\n",
    "\n",
    "    alloc_size : tuple of int\n",
    "        Allocate size for the anchor boxes as (H, W).\n",
    "        Usually we generate enough anchors for large feature map, e.g. 128x128.\n",
    "        Later in inference we can have variable input sizes,\n",
    "        at which time we can crop corresponding anchors from this large\n",
    "        anchor map so we can skip re-generating anchors for each input.\n",
    "    '''\n",
    "\n",
    "    def __init__(self,  stride, base_size, scales, ratios, alloc_size):\n",
    "        if not base_size:\n",
    "            raise ValueError(\"Invalid base_size: {}.\".format(base_size))\n",
    "        if not isinstance(ratios, (tuple, list)):\n",
    "            ratios = [ratios]\n",
    "        if not isinstance(scales, (tuple, list)):\n",
    "            scales = [scales]\n",
    "        corner = [0, 0, base_size-1, base_size-1]\n",
    "        super().__init__(corner)\n",
    "        self.ratios = ratios\n",
    "        self.scales = scales\n",
    "        self.alloc_size = alloc_size\n",
    "        self.stride = stride\n",
    "\n",
    "    @property\n",
    "    def base_sizes(self):\n",
    "        base_sizes = []\n",
    "        px, py = self.whctrs\n",
    "        for r in self.ratios:\n",
    "            for s in self.scales:\n",
    "                ratio_size = self.size/r\n",
    "                ws = np.round(np.sqrt(ratio_size))\n",
    "                hs = np.round(ws * r)\n",
    "                w = (ws * s - 1) * 0.5\n",
    "                h = (hs * s - 1) * 0.5\n",
    "                base_sizes.append([px - w, py - h, px + w, py + h])\n",
    "        return np.array(base_sizes)\n",
    "\n",
    "    @property\n",
    "    def anchors(self):\n",
    "        height, width = self.alloc_size\n",
    "        offset_x = np.arange(0, width * self.stride, self.stride)\n",
    "        offset_y = np.arange(0, height * self.stride, self.stride)\n",
    "        offset_x, offset_y = np.meshgrid(offset_x, offset_y)\n",
    "        offsets = np.stack((offset_x.ravel(), offset_y.ravel(),\n",
    "                            offset_x.ravel(), offset_y.ravel()), axis=1)\n",
    "        # broadcast_add (1, N, 4) + (M, 1, 4)\n",
    "        anchors = (self.base_sizes.reshape((1, -1, 4)) +\n",
    "                   offsets.reshape((-1, 1, 4)))\n",
    "        anchors = anchors.reshape((1, 1, height, width, -1)).astype(np.float32)\n",
    "        return anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_size = 16\n",
    "stride = 16  # 特征图的每个像素感受野大小，通常为原图和特征图尺寸比例\n",
    "scales = [8, 16, 32]  # 尺度，面积比\n",
    "ratios = [0.5, 1, 2]  # window（滑动窗口） 与锚框的面积的比率（aspect ratios）\n",
    "alloc_size = (50, 50)  # 默认的特征图大小(H,W)，以后每次生成直接索引切片\n",
    "A = Anchor(stride, base_size, scales, ratios, alloc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon, nd\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class RPNAnchorGenerator(gluon.HybridBlock):\n",
    "    def __init__(self, anchors, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._num_depth = len(A.ratios) * len(A.scales)\n",
    "        self.anchors = self.params.get_constant('anchor_', A.anchors)\n",
    "        \n",
    "    @property\n",
    "    def num_depth(self):\n",
    "        \"\"\"Number of anchors at each pixel.\"\"\"\n",
    "        return self._num_depth\n",
    "\n",
    "    # pylint: disable=arguments-differ\n",
    "    def hybrid_forward(self, F, x, anchors):\n",
    "        \"\"\"Slice anchors given the input image shape.\n",
    "\n",
    "        Inputs:\n",
    "            - **x**: input tensor with (1 x C x H x W) shape.\n",
    "        Outputs:\n",
    "            - **out**: output anchor with (1, N, 4) shape. N is the number of anchors.\n",
    "\n",
    "        \"\"\"\n",
    "        a = F.slice_like(anchors, x * 0, axes=(2, 3))\n",
    "        return a.reshape((1, -1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_generator = RPNAnchorGenerator(A)\n",
    "anchor_generator.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nd.ones((1, 3, 22, 22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[[ -84.  -40.   99.   55.]\n",
       "  [-176.  -88.  191.  103.]\n",
       "  [-360. -184.  375.  199.]\n",
       "  ...\n",
       "  [ 300.  256.  387.  431.]\n",
       "  [ 256.  168.  431.  519.]\n",
       "  [ 168.   -8.  519.  695.]]]\n",
       "<NDArray 1x4356x4 @cpu(0)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_generator(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RPNAnchorGenerator(\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RPN(gluon.HybridBlock):\n",
    "    r\"\"\"Region Proposal Network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    channels : int\n",
    "        Channel number used in convolutional layers.\n",
    "    stride : int\n",
    "        Feature map stride with respect to original image.\n",
    "        This is usually the ratio between original image size and feature map size.\n",
    "    base_size : int\n",
    "        The width(and height) of reference anchor box.\n",
    "    scales : iterable of float\n",
    "        The areas of anchor boxes.\n",
    "        We use the following form to compute the shapes of anchors:\n",
    "\n",
    "        .. math::\n",
    "\n",
    "            width_{anchor} = size_{base} \\times scale \\times \\sqrt{ 1 / ratio}\n",
    "            height_{anchor} = size_{base} \\times scale \\times \\sqrt{ratio}\n",
    "\n",
    "    ratios : iterable of float\n",
    "        The aspect ratios of anchor boxes. We expect it to be a list or tuple.\n",
    "    alloc_size : tuple of int\n",
    "        Allocate size for the anchor boxes as (H, W).\n",
    "        Usually we generate enough anchors for large feature map, e.g. 128x128.\n",
    "        Later in inference we can have variable input sizes,\n",
    "        at which time we can crop corresponding anchors from this large\n",
    "        anchor map so we can skip re-generating anchors for each input.\n",
    "    clip : float\n",
    "        Clip bounding box target to this value.\n",
    "    nms_thresh : float\n",
    "        IOU threshold for NMS. It is used to remove overlapping proposals.\n",
    "    train_pre_nms : int\n",
    "        Filter top proposals before NMS in training.\n",
    "    train_post_nms : int\n",
    "        Return top proposal results after NMS in training.\n",
    "    test_pre_nms : int\n",
    "        Filter top proposals before NMS in testing.\n",
    "    test_post_nms : int\n",
    "        Return top proposal results after NMS in testing.\n",
    "    min_size : int\n",
    "        Proposals whose size is smaller than ``min_size`` will be discarded.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels, A,\n",
    "                 clip, nms_thresh, train_pre_nms, train_post_nms,\n",
    "                 test_pre_nms, test_post_nms, min_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        weight_initializer = mx.init.Normal(0.01)\n",
    "        with self.name_scope():\n",
    "            self.anchor_generator = RPNAnchorGenerator(A)\n",
    "            anchor_depth = self.anchor_generator.num_depth\n",
    "            self.region_proposaler = RPNProposal(\n",
    "                clip, nms_thresh, train_pre_nms, train_post_nms,\n",
    "                test_pre_nms, test_post_nms, min_size, stds=(1., 1., 1., 1.))\n",
    "            self.conv1 = nn.HybridSequential()\n",
    "            self.conv1.add(nn.Conv2D(channels, 3, 1, 1,\n",
    "                                     weight_initializer=weight_initializer))\n",
    "            self.conv1.add(nn.Activation('relu'))\n",
    "            # use sigmoid instead of softmax, reduce channel numbers\n",
    "            self.score = nn.Conv2D(anchor_depth, 1, 1, 0,\n",
    "                                   weight_initializer=weight_initializer)\n",
    "            self.loc = nn.Conv2D(anchor_depth * 4, 1, 1, 0,\n",
    "                                 weight_initializer=weight_initializer)\n",
    "\n",
    "    # pylint: disable=arguments-differ\n",
    "    def hybrid_forward(self, F, x, img):\n",
    "        \"\"\"Forward RPN.\n",
    "\n",
    "        The behavior during traing and inference is different.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : mxnet.nd.NDArray or mxnet.symbol\n",
    "            Feature tensor.\n",
    "        img : mxnet.nd.NDArray or mxnet.symbol\n",
    "            The original input image.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        (rpn_score, rpn_box)\n",
    "            Returns predicted scores and regions which are candidates of objects.\n",
    "\n",
    "        \"\"\"\n",
    "        anchors = self.anchor_generator(x)\n",
    "        x = self.conv1(x)\n",
    "        raw_rpn_scores = self.score(x).transpose(axes=(0, 2, 3, 1)).reshape((0, -1, 2))\n",
    "        rpn_scores = F.sigmoid(F.stop_gradient(raw_rpn_scores))\n",
    "        rpn_box_pred = self.loc(x).transpose(\n",
    "            axes=(0, 2, 3, 1)).reshape((0, -1, 4))\n",
    "        rpn_score, rpn_box = self.region_proposaler(\n",
    "            anchors, rpn_scores, F.stop_gradient(rpn_box_pred), img)\n",
    "        if autograd.is_training():\n",
    "            # return raw predictions as well in training for bp\n",
    "            return rpn_score, rpn_box, raw_rpn_scores, rpn_box_pred, anchors\n",
    "        return rpn_score, rpn_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluoncv",
   "language": "python",
   "name": "gluoncv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
