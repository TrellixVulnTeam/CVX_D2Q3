{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实战 Kaggle 比赛：CIFAR-10 分类（Keras 版）\n",
    "\n",
    "本章将使用 Keras 动手实战 CIFAR-10 图像分类，该任务是一个多分类任务。该任务的网页地址是 https://www.kaggle.com/c/cifar-10 。\n",
    "\n",
    "思考：将 CIFAR-10 封装为 HDF5（可参考：https://www.cnblogs.com/q735613050/p/9244223.html）\n",
    "\n",
    "> 本章快报：\n",
    "\n",
    "## 8.1 数据处理\n",
    "\n",
    "从 Data Description（https://www.kaggle.com/c/cifar-10/data ）可获知：\n",
    "\n",
    "人们熟知的 CIFAR-10 数据包含 $60\\,000$ 张 $32\\times 32$ 的彩色图片。该数据总共有 $10$ 个类别，每个类别下均有 $6000$ 张图片。其中，训练集和测试集占比为 $5:1$。Kaggle 比赛“CIFAR-10 - Object Recognition in Images”则提供了更多的数据。\n",
    "\n",
    "- train.7z：和官方提供的一致\n",
    "- test.7z：增加了 $290,000$ 张图片\n",
    "- trainLabels.csv：训练集的标签\n",
    "\n",
    "由于 Keras 的局限性（自定义数据迭代器很不方便），需要将数据集进行解压。先载入一些必备包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-25T02:12:49.730866Z",
     "start_time": "2019-01-25T02:12:48.350860Z"
    }
   },
   "outputs": [],
   "source": [
    "import zipfile  # 处理压缩文件\n",
    "import os\n",
    "\n",
    "import pandas as pd  # 处理 csv 文件\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解压已经下载好的数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-25T02:12:54.209878Z",
     "start_time": "2019-01-25T02:12:54.205895Z"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = r'E:\\Data\\Kaggle'\n",
    "#from utils.kaggle.helper import unzip\n",
    "#dataDir = unzip(base_dir, dataDir)  # 解压 all.zip \n",
    "dataDir = os.path.join(base_dir, 'Cifar10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T02:39:04.003687Z",
     "start_time": "2019-01-19T02:39:04.000682Z"
    }
   },
   "source": [
    "解压后的数据存在 `.7z` 文件，故而需要下载 7-Zip（https://sparanoid.com/lab/7z/ ）来继续解压数据。解压好之后，继续对数据继续处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-25T02:12:57.793288Z",
     "start_time": "2019-01-25T02:12:57.782297Z"
    }
   },
   "outputs": [],
   "source": [
    "class CSVCat:\n",
    "    def __init__(self, root, name):\n",
    "        self.csv2dict(root, name)  # name 是 .csv 文件\n",
    "\n",
    "    @staticmethod\n",
    "    def read_csv(root, name):\n",
    "        return pd.read_csv(os.path.join(root,\n",
    "                                        name))  # 从本地读取标签信息，格式 (id, label)\n",
    "\n",
    "    def csv2dict(self, root, name):\n",
    "        rec = CSVCat.read_csv(root, name).to_records()  # 将 CSV 转换为 Records\n",
    "        self.cat_dict = {}  # 格式为 {'cat':[id1, id2, ...], ...}\n",
    "        for _, p, class_name in rec:\n",
    "            self.cat_dict[class_name] = self.cat_dict.get(class_name,\n",
    "                                                          []) + [p]  # 列表加法\n",
    "        self.class_names = tuple(self.cat_dict.keys())  # 获取类别名称列表\n",
    "\n",
    "    def split(self, test_size=.3):\n",
    "        import random\n",
    "        train_dict = {}\n",
    "        val_dict = {}\n",
    "        test_size = .3\n",
    "        for class_name, id_list in self.cat_dict.items():\n",
    "            random.shuffle(id_list)\n",
    "            n = len(id_list)\n",
    "            test_num = int(n * test_size)\n",
    "            val_dict[class_name], train_dict[\n",
    "                class_name] = id_list[:test_num], id_list[test_num:]\n",
    "        return train_dict, val_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSVCat 被封装进了 zipimage 模块中。下面将利用该类来划分数据集并获取类别名称列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-25T02:13:02.718274Z",
     "start_time": "2019-01-25T02:13:01.297427Z"
    }
   },
   "outputs": [],
   "source": [
    "cat = CSVCat(dataDir, 'trainLabels.csv') # 实例化\n",
    "class_names = cat.class_names  # 获取类别名称列表\n",
    "train_dict, val_dict = cat.split()  # 划分数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T07:06:19.410976Z",
     "start_time": "2019-01-19T07:06:19.407019Z"
    }
   },
   "source": [
    "为了代码的简洁，下面先定义两个辅助函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-25T02:13:05.616217Z",
     "start_time": "2019-01-25T02:13:05.609252Z"
    }
   },
   "outputs": [],
   "source": [
    "def mkdir_if_not_exist(root, dir_name):\n",
    "    # 在 root 下生成目录\n",
    "    _dir = os.path.join(root, dir_name) # 拼出分完整目录名\n",
    "    if not os.path.exists(_dir):  # 是否存在目录，如果没有创建\n",
    "        os.makedirs(_dir)\n",
    "    return _dir\n",
    "\n",
    "def copyfile(original_dir, obj_dir, fnames):\n",
    "    import shutil\n",
    "    # 将 original_dir 目录下的 fnames 复制到 obj_dir\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(original_dir, fname)\n",
    "        dst = os.path.join(obj_dir, fname)\n",
    "        shutil.copyfile(src, dst)   # 复制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mkdir_if_not_exist` 函数用来创建目录，而 `copyfile` 则从源数据中划分出训练集和验证集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-25T02:13:14.727946Z",
     "start_time": "2019-01-25T02:13:14.672972Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor label, id_list in train_dict.items():\\n    trainDir = mkdir_if_not_exist(baseDir, f'train/{label}')\\n    fnames = [f'{p}.png' for p in id_list]\\n    copyfile(oriDir, trainDir, fnames)  # 从源数据复制训练数据\\n    \\nfor label, id_list in val_dict.items():\\n    valDir = mkdir_if_not_exist(baseDir, f'val/{label}')\\n    fnames = [f'{p}.png' for p in id_list] \\n    copyfile(oriDir, valDir, fnames)  # 从源数据复制验证数据\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseDir = mkdir_if_not_exist(dataDir, 'data')  # 根目录\n",
    "oriDir = os.path.join(dataDir, 'train')  # 源目录\n",
    "\n",
    "'''\n",
    "for label, id_list in train_dict.items():\n",
    "    trainDir = mkdir_if_not_exist(baseDir, f'train/{label}')\n",
    "    fnames = [f'{p}.png' for p in id_list]\n",
    "    copyfile(oriDir, trainDir, fnames)  # 从源数据复制训练数据\n",
    "    \n",
    "for label, id_list in val_dict.items():\n",
    "    valDir = mkdir_if_not_exist(baseDir, f'val/{label}')\n",
    "    fnames = [f'{p}.png' for p in id_list] \n",
    "    copyfile(oriDir, valDir, fnames)  # 从源数据复制验证数据\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面可以利用 Keras 的 `ImageDataGenerator` 来直接读取数据，并加入一些数据增强的处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-25T02:13:44.619600Z",
     "start_time": "2019-01-25T02:13:21.017652Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35000 images belonging to 10 classes.\n",
      "Found 15000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,  # 将数据的数值归一化到 [0, 1]\n",
    "      rotation_range=40,  # 图像随机旋转的角度\n",
    "      width_shift_range=0.2,  # 图像在水平方向平移的范围\n",
    "      height_shift_range=0.2,  # 图像在垂直方向平移的范围\n",
    "      shear_range=0.2,        # 随机错切变换的角度\n",
    "      zoom_range=0.2,       # 随机缩放的范围\n",
    "      horizontal_flip=True,  # 随机水平翻转\n",
    "      fill_mode='nearest')   # 填充新创建像素\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) # 注意，不能增强验证数据\n",
    "\n",
    "train_dir = os.path.join(baseDir, 'train')   # 训练数据所在路径\n",
    "validation_dir = os.path.join(baseDir, 'val')  # 验证数据所在路径\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, batch_size=20, target_size=(32, 32), classes=class_names) # 将所有图像的大小调整为 32 x 32\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir, target_size=(32, 32), batch_size=20, classes=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 使用预训练的基网络来训练模型\n",
    "\n",
    "使用预训练基网络的方法有：\n",
    "\n",
    "- 特征提取（feature extraction）\n",
    "- 微调模型（fine-tuning）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T02:38:02.869099Z",
     "start_time": "2019-01-24T02:37:57.487429Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "conv_base = VGG16(include_top=False, weights='imagenet', classes=10) # 卷积基"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T11:10:46.754270Z",
     "start_time": "2019-01-19T11:10:46.672254Z"
    }
   },
   "source": [
    "参数：\n",
    "\n",
    "- `include_top`: 是否包括顶层的全连接层\n",
    "- `weights`：指定模型初始化的权重检查点\n",
    "- `input_shape`：网络的输入张量的 shape\n",
    "- `classes`：类别个数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-19T12:34:31.710618Z",
     "start_time": "2019-01-19T12:34:31.696676Z"
    }
   },
   "source": [
    "我们可以看看**卷积基**（在诸如 imagenet 上训练过的网络的除去其顶层全连接部分）的详细结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T02:38:04.326811Z",
     "start_time": "2019-01-24T02:38:04.317809Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T02:34:37.547003Z",
     "start_time": "2019-01-24T02:34:01.344Z"
    }
   },
   "outputs": [],
   "source": [
    "for inputs, labels in train_generator:\n",
    "    train_features = conv_base.predict(inputs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T02:34:37.548005Z",
     "start_time": "2019-01-24T02:34:01.403Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_feaures(data_generator):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for input_batch, label_batch in data_generator:\n",
    "        features.append(conv_base.predict(input_batch))\n",
    "        labels.append(label_batch)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T02:34:37.550000Z",
     "start_time": "2019-01-24T02:34:01.502Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_features, train_labels = extract_feaures(train_generator)\n",
    "validation_features, validation_labels = extract_feaures(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras tensorflow",
   "language": "python",
   "name": "keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
